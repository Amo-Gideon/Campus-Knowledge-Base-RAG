{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a921343d",
   "metadata": {},
   "source": [
    "##### Retrieval Augmented Generation Chatbot: Campus Knowledge Base Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704fe66",
   "metadata": {},
   "source": [
    "##### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b101914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.vectorstores import Chroma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ec6f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'llama3.2:3b'\n",
    "db_name = 'chroma_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded 11 documents\n"
     ]
    }
   ],
   "source": [
    "# --- Load Documents ---\n",
    "files = glob.glob('../knowledge_base*')\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "documents = []\n",
    "\n",
    "for file in files:\n",
    "    doc_type = os.path.basename(file)\n",
    "    loader = DirectoryLoader(\n",
    "        '../knowledge_base',\n",
    "        glob='*.txt',\n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs=text_loader_kwargs\n",
    "    )\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata['doc_type'] = doc_type\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\" Successfully loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aafa441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 11 chunks\n"
     ]
    }
   ],
   "source": [
    "# --- Split into Chunks ---\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5e88098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb6370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: knowledge_base\n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63f76543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Chroma Vector Store ---\n",
    "embeddings = OllamaEmbeddings(model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85d8cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ChromaDB created at: chroma_db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Appau Amo\\AppData\\Local\\Temp\\ipykernel_10136\\3678966243.py:7: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "# Store persistently in a folder (optional for reloading later)\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=db_name\n",
    ")\n",
    "vectorstore.persist()\n",
    "print(f\" ChromaDB created at: {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6671cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Appau Amo\\AppData\\Local\\Temp\\ipykernel_10136\\1273460715.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# --- Setup Conversational Retrieval ---\n",
    "llm = ChatOllama(model=MODEL)\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ebc3494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAMUSTED is a premier institution for STEM and Education in the region, established in 2018 with recognition from the National Accreditation Board (NAB). It offers a unique curriculum designed to meet the challenges of the 21st century, situated on a 200-acre campus in Kumasi. The university is led by Chancellor Dr. Nana Abena Mensah, who provides strategic direction and oversight for its academic and administrative functions.\n"
     ]
    }
   ],
   "source": [
    "query = 'Can you tell me about AAMUSTED in few sentences?'\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d9bbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Chat Function for Gradio ---\n",
    "def chat(message, history):\n",
    "    result = conversation_chain.invoke({\"question\": message})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "128f9f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Launch Gradio Chat UI ---\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "del_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
